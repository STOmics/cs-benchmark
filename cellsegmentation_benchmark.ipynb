{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "737b2d00-7766-4dbe-b118-7151d43749a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T03:14:11.017405Z",
     "iopub.status.busy": "2023-12-18T03:14:11.016461Z",
     "iopub.status.idle": "2023-12-18T03:14:11.064280Z",
     "shell.execute_reply": "2023-12-18T03:14:11.061937Z",
     "shell.execute_reply.started": "2023-12-18T03:14:11.017248Z"
    }
   },
   "source": [
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://gitee.com/niov/STOCNSFs/raw/main/cs_benchmark/precision.png\" width=80% height=80% alt=\"\" />\n",
    "    <h4>\n",
    "      Cell Segmentation: How to choose tools that match your stereo-seq data\n",
    "    </h4>\n",
    "</div>\n",
    "\n",
    "# What Is Cell Segmentation?\n",
    "The difficulty of achieving accurate, automated cell segmentation is due in large part to the differences in cell shape, size and density across tissue types.Deep learning algorithms for computer vision are increasingly being used for a variety of tasks in biological image analysis, including nuclear and cell segmentation. Based on these, we will explore which segmentation algorithm is more suitable for stereo-seq image data.\n",
    "\n",
    "**Journal**: bioRxiv<br>\n",
    "**Doi**: https://doi.org/10.1101/2023.08.08.552402<br>\n",
    "**Published Date**: Dec 27, 2023<br>\n",
    "**Github**: -<br>\n",
    "**Tutorial**: -<br>\n",
    "**Environment（mirror）**：cs_benchmark (URL: https://cloud.stomics.tech/#/public/image)<br>\n",
    "\n",
    "# Tutorial\n",
    "\n",
    "## Input and Output\n",
    "\n",
    "We have deployed the following 5 cell segmentation methods:\n",
    "\n",
    "> [Cellpose](https://github.com/MouseLand/cellpose) is a generalist algorithm for cellular segmentation.<br>\n",
    "> [DeepCell](https://github.com/vanvalenlab/deepcell-tf) is a deep learning library for single-cell analysis of biological images. Here, pre-trained DeepCell models are used for cell/nuclei segmentation from raw image data.<br><br>\n",
    "> [StereoCell](https://github.com/STOmics/StereoCell/tree/dev) is an open-source software for measuring and analyzing cell images. Here, CellProfiler is used for object detection and region growth-based object segmentation.<br><br>\n",
    "> [SAM](https://github.com/facebookresearch/segment-anything) is an open-source software for measuring and analyzing cell images. Here, CellProfiler is used for object detection and region growth-based object<br><br>\n",
    "> [LT](https://github.com/BGI-DEV-REG/ARTISTA) is an open-source software for measuring and analyzing cell images. Here, CellProfiler is used for object detection and region growth-based object.<br><br>\n",
    "\n",
    "The main parameters of the program include,\n",
    "- Input\n",
    "\n",
    "    - ```is_gpu```: Use GPU or not<br>\n",
    "    - ```method```: segmentation methods, ['deepcell', 'cellpose', 'stereocell', 'sam', 'lt']<br>\n",
    "    - ```image_path```: Stereo-seq Image data<br>\n",
    "\n",
    "- Output\n",
    "\n",
    "    - ```output_path```: result of cell segmentation\n",
    "\n",
    "## Demo Data\n",
    "\n",
    "Here, we present the StereoCell cell segmentation test dataset to compare the performance of different segmentation methods. Recent studies have shown that the diversity of data modalities, complex differences in image backgrounds, and cell distribution and morphology pose great challenges to segmentation methods. Therefore, we chose imaging data under [stereo-seq]() technology to construct a test set, covering 4 staining methods, namely: ssDNA, [HE](), [FB]() and [mIF](); all 42 ROIs in the test set come from 11 animal sections and 1 plant tissue sample. The test dataset is available at https://datasets.deepcell.org/ for noncommercial use.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"docs/slice.png\" width=60% height=60% alt=\"Fig StereoCell benchmarking\" />\n",
    "    <h6>\n",
    "      Fig 1 Benchmarking for stereo-seq Image Data\n",
    "    </h6>\n",
    "</div>\n",
    "\n",
    "\n",
    "## Time Estimates\n",
    "<div align=\"center\">\n",
    "    <img src=\"docs/time.png\" align=\"right\" width=40% height=40% alt=\"\" />\n",
    "    <br>\n",
    "</div>\n",
    "It can be seen from the test data that the traditional method is much faster than the deep learning method. Under the deep learning method, the time consumption of cellpose and deepcell is similar, and stereocell is faster. The SAM time consumption of large visual models is relatively long.\n",
    "\n",
    "| Method |CPU Core|CPU Memory (Gb)|GPU Memory (Gb)|Running Time (min)|\n",
    "|:--:|:--:|:--:|:--:|:--:|\n",
    "|LT|32|32|0|5~10|\n",
    "|SAM|32|32|0|5~10|\n",
    "|StereoCell|32|32|0|5~10|\n",
    "|Cellpose|32|32|0|5~10|\n",
    "|Deepcell|32|32|0|5~10|\n",
    "</div>\n",
    "\n",
    "# Benchmarking\n",
    "\n",
    "## Index\n",
    "<div align=\"center\">\n",
    "    <img src=\"docs/seg.png\" width=50% height=50% alt=\"Single-cell Stereo-seq reveals induced progenitor cells involved in axolotl brain regeneration\" />\n",
    "    <h6>\n",
    "      Fig 2 precision and recall for cell segmentation\n",
    "    </h6>\n",
    "</div>\n",
    "\n",
    "To evaluate the relative performance of different deep learning architectures, we compared several alternatives: StereoCell (kernel), Deepcell (whole-cell), Cellpose (whole-cell), SAM (whole-cell), and LT. All methods are evaluated on the StereoCell test set.\n",
    " - n_pred,\n",
    " - n_true,\n",
    " - precision,\n",
    " - recall,\n",
    " - F1,\n",
    "\n",
    "## Result\n",
    "<div align=\"center\">\n",
    "    <img src=\"docs/precision.png\" width=80% height=80% alt=\"Single-cell Stereo-seq reveals induced progenitor cells involved in axolotl brain regeneration\" />\n",
    "    <h6>\n",
    "      Fig 3 Benchmarking for stereo-seq Image Data\n",
    "    </h6>\n",
    "</div>\n",
    "\n",
    "We evaluate 5 popular cell segmentation methods on the StereoCell test dataset, including their segmentation levels and algorithm performance. From the F1 score of each algorithm, the following recommended solutions can be obtained:\n",
    " - scene 1: If the data is **ssDNA staining**, we recommend using the _StereoCell_ cell segmentation algorithm\n",
    "\n",
    " - scene 2: If the data is **HE/mIF** stained, we recommend using the _Deepcell/Cellpose_ cell segmentation algorithm\n",
    "\n",
    "  - scene 3: If the data is **FB** stained, we recommend using the _Deepcell/StereoCell/Cellpose_ cell segmentation algorithm\n",
    "\n",
    "  - scene 4: Under **ssDNA/HE** staining, the segmentation results need to be adjusted to the optimal segmentation results. It is recommended to use the _LT algorithm_ and realize it through parameter adjustment.\n",
    "\n",
    "All in all, **Cellpose** and **Deepcell** are more universal.\n",
    "\n",
    "## Supplementary information\n",
    "\n",
    "| Species | StereoCell | DeepCell | Cellpose | SAM | LT |\n",
    "|--------: | :---------:|:--------:| :---------:|:--------:|:--------:|\n",
    "| HE/mouse_stomach | 0.14831 | 0.00965 |  0.00103 | 0.27114 | 0.02818 |\n",
    "| HE/human_ovarian_cancer | 0.57156 | 0.0197 |  0.34593 | 0.29969 | 0.12209 |\n",
    "| HE/mouse_large_intestine | 0.12297 | 0.00691 |  0.0155 | 0.31266 | 0.02818 |\n",
    "| HE/human_stomach_cancer | 0.25906 | 0.00238 |  0.03362 | 0.31374 | 0.04236 |\n",
    "| HE/mouse_brain | 0.48167 | 0.00483 |  0.32376 | 0.48882 | 0.24997 |\n",
    "| HE/human_melanoma | 0.51569 | 0.01312 |  0.30805 | 0.44213 | 0.16007 |\n",
    "| FB/arabidopsis_thaliana_seeds | 0.11188 | 0.03638 |  0.71235 | 0.20158 | 0.10615 |\n",
    "| ssDNA/murine_kidney | 0.50257 | 0.48804 |  0.58297 | 0.30123 | 0.18944 |\n",
    "| ssDNA/mouse_placenta | 0.34727 | 0.50867 |  0.56316 | 0.2437 | 0.22016 |\n",
    "| ssDNA/mouse_brain | 0.41138 | 0.43785 |  0.54767 | 0.30734 | 0.23151 |\n",
    "| ssDNA/human_liver | 0.44711 | 0.48498 |  0.5488 | 0.32185 | 0.17862 |\n",
    "| ssDNA/murine_prostate | 0.58785 | 0.67761 |  0.72194 | 0.36294 | 0.19122 |\n",
    "| mIF/mouse_liver | 0.02789 | 0.01132 |  0.67243 | 0.25676 | 0.13448 |\n",
    "\n",
    "# Acknowledgements\n",
    "\n",
    "We thank: \n",
    "\n",
    "- [Cellpose_Cell_Segmentation_Tutorial](https://cloud.stomics.tech/#/public/tool/app-detail/notebook/224/--)\n",
    "- [DeepCell_Cell_Segmentation](https://cloud.stomics.tech/#/public/tool/app-detail/notebook/233/--)\n",
    "- [StereoCell_Cell_Segmentation](https://cloud.stomics.tech/#/public/tool/app-detail/notebook/222/--)\n",
    "- [SAM_Cell_Segmentation](https://cloud.stomics.tech/#/public/tool/app-detail/notebook/206/--)\n",
    "- [LT_Cell_Segmentation](https://cloud.stomics.tech/#/public/tool/app-detail/notebook/79/--)\n",
    "\n",
    "# Appendix\n",
    "\n",
    "**cs_benchmark** uses conda's multi-environment solution to meet users' needs to call multiple segmentation methods at the same time. The details of the environment construction are listed below:\n",
    "\n",
    "<details close>\n",
    "<summary>CellPose</summary>\n",
    "\n",
    "```text\n",
    "source activate \n",
    "conda deactivate\n",
    "conda create -n cellpose python=3.8\n",
    "conda activate cellpose\n",
    "pip install torch\n",
    "pip install torchvision\n",
    "pip install cellpose\n",
    "pip install tifffile\n",
    "pip install patchify\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details close>\n",
    "<summary>DeepCell</summary>\n",
    "\n",
    "```text\n",
    "source activate \n",
    "conda deactivate\n",
    "conda create -n deepcell python=3.8\n",
    "conda activate deepcell\n",
    "pip install DeepCell==0.12.9\n",
    "pip install tifffile>=2023.2.3\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details close>\n",
    "<summary>StereoCell</summary>\n",
    "\n",
    "```text\n",
    "source activate \n",
    "conda deactivate\n",
    "conda create -n stereocell python=3.8\n",
    "conda activate stereocell\n",
    "pip install onnxruntime>=1.15.1\n",
    "pip install tifffile>=2023.2.3\n",
    "pip install scikit-image>=0.21.0\n",
    "pip install opencv-python>=4.8.0.76\n",
    "pip install tqdm\n",
    "pip install stio==0.1.0 --no-deps\n",
    "pip install cell-bin==1.2.5 --no-deps\n",
    "pip install stio==0.1.0 --no-deps\n",
    "pip install requests\n",
    "mkdir /home/weights\n",
    "python -c \"from cellbin.dnn.weights import auto_download_weights, WEIGHTS; auto_download_weights('/home/weights', WEIGHTS.keys())\"\n",
    "\n",
    "```\n",
    "</details>\n",
    "\n",
    "\n",
    "<details close>\n",
    "<summary>SAM</summary>\n",
    "\n",
    "```text\n",
    "\n",
    "source activate \n",
    "conda deactivate\n",
    "conda create -n sam python=3.8\n",
    "conda activate sam\n",
    "pip install https://ghproxy.com/https://github.com/facebookresearch/segment-anything.git\n",
    "pip install opencv-python pycocotools matplotlib onnxruntime onnx\n",
    "pip install torch torchvision scipy tifffile tqdm -i https://mirrors.ustc.edu.cn/pypi/web/simple/\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details close>\n",
    "<summary>Eval</summary>\n",
    "\n",
    "```text\n",
    "pip install cython six openpyxl\n",
    "cd eval\n",
    "python setup.py install --user\n",
    "```\n",
    "    \n",
    "</details>\n",
    "\n",
    "# Running\n",
    "\n",
    "sam ran for a total of 4769.733977794647 s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46eb77ac-7a65-47be-a441-acaf1814eae7",
   "metadata": {},
   "source": [
    "## 分割细胞\n",
    "图片名字要求带_img，mask图片要求名字_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b233ba-eb0d-45da-b0b4-9ce3d82703d4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import subprocess\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "work_path = os.path.abspath('.')\n",
    "# work_path = '/data/work/benchmark/benchmark'\n",
    "__py__ = {\n",
    "    'MEDIAR':'anaconda3/envs/MEDIAR/bin/python',\n",
    "    'cellpose': 'anaconda3/envs/cellpose/bin/python',\n",
    "    'cellpose3':'anaconda3/envs/cellpose3/bin/python',\n",
    "    'deepcell': 'anaconda3/envs/deepcell/bin/python',\n",
    "    'sam': 'anaconda3/envs/sam/bin/python',\n",
    "    'stardist':'anaconda3/envs/stardist/bin/python',\n",
    "}\n",
    "__methods__ = ['MEDIAR','cellpose','cellpose3', 'sam','stardist']\n",
    "\n",
    "\n",
    "__script__ = {\n",
    "    'MEDIAR':os.path.join(work_path,'src/methods/MEDIAR/MEDIAR/iMEDIAR.py'),\n",
    "    'cellpose': os.path.join(work_path, 'src/methods/cellpose/icellpose.py'),\n",
    "    'cellpose3':os.path.join(work_path,'src/methods/cellpose3/icellpose.py'),\n",
    "    'deepcell': os.path.join(work_path, 'src/methods/deepcell/ideepcell2.py'),\n",
    "    'sam': os.path.join(work_path, 'src/methods/sam/isam.py'),\n",
    "    'stardist':os.path.join(work_path,'src/methods/stardist/istardist.py')\n",
    "}\n",
    "# ############################### 图片名字要求带-img，mask图片要求名字-mask\n",
    "\n",
    "#method = ['sam','cellpose3','cellpose','MEDIAR']\n",
    "#method= ['MEDIAR','cellpose','sam','cellpose3','v3']\n",
    "\n",
    "#######你需要修改的部分#####\n",
    "is_gpu = True\n",
    "method = ['cellpose','cellpose3','MEDIAR','sam','stardist','deepcell']\n",
    "image_path = ''\n",
    "output_path = ''\n",
    "img_type = 'ss' # he or ss\n",
    "###########################\n",
    "print(os.listdir(image_path))\n",
    "print(work_path)\n",
    "\n",
    "for m in method: assert m in __methods__\n",
    "for m in method:\n",
    "    start = time.time()\n",
    "    cmd = '{} {} -i {} -o {} -g {} -t {}'.format(__py__[m], __script__[m], \n",
    "                                    image_path, os.path.join(output_path, m), is_gpu, img_type)\n",
    "    print(cmd)\n",
    "    os.system(cmd)\n",
    "    t = time.time() - start\n",
    "    print('{} ran for a total of {} s'.format(m, t))\n",
    "    print('{} result saved to {}'.format(m, os.path.join(output_path, m)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ccaeb1-01b1-4cce-8fe7-d4ffd54f9f0e",
   "metadata": {},
   "source": [
    "## 评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89daaee6-048a-460f-91cf-ef4789f6cac3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluation\n",
    "import os\n",
    "\n",
    "py = '/storeData/USER/data/01.CellBin/00.user/fanjinghong/home/anaconda3/envs/benchmark/bin/python'\n",
    "script = '/storeData/USER/data/01.CellBin/00.user/fanjinghong/code/benchmark2/src/eval/cell_eval_multi.py'\n",
    "\n",
    "gt_path = '/storeData/USER/data/01.CellBin/00.user/shican/benchmark_new/dataset/ssDNA/gt'\n",
    "dt_path = '/storeData/USER/data/01.CellBin/00.user/fanjinghong/code/benchmark2/input/ssDNA/gaussian_blur_output_3'\n",
    "eval_path = '/storeData/USER/data/01.CellBin/00.user/fanjinghong/code/benchmark2/input/ssDNA/gaussian_blur_eval_3'\n",
    "if not os.path.exists(eval_path): os.makedirs(eval_path)\n",
    "\n",
    "cmd = '{} {} -g {} -d {} -o {}'.format(py, script, gt_path, dt_path, eval_path)\n",
    "print(cmd)\n",
    "os.system(cmd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bb528a-2028-4faa-a457-0a3ae37a0665",
   "metadata": {},
   "source": [
    "# **Contact Information**\n",
    "For questions about this notebook, please contact: _cloud@stomics.tech_.\n",
    "\n",
    "# **Cite**\n",
    "If you use STOmics/Stereo-seq data in your research, please considering referring us in your article:\n",
    "> **Code available** The source code of this algorithm is available at Github (https://github.com/BGI-DEV-REG/ARTISTA). The visual and convenient execution of this algorithm can be found from STOmics Cloud Platform (https://cloud.stomics.tech/).\n",
    "\n",
    "> **Acknowledgement** We express our gratitude to the computing platform STOmics Cloud (https://cloud.stomics.tech/) for enabling workflow automation and accelerating Stereo-seq data analysis. If you use STOmics/Stereo-seq data in your research, please considering referring us in your article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4fd987-afce-40d4-bbb8-2eb984f2f951",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install compute_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85cbe87-2fa0-463f-92a6-3685d46ea69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd src/eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c89990-1416-4b2a-b6f6-5814cc607d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "python setup.py install --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ad1739-5b04-499b-aad1-d101da992a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benchmark",
   "language": "python",
   "name": "benchmark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
